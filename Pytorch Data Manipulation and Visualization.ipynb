{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0512391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision #Contains neural network training datasets\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c64fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a870c6c8b842d7bddb817930219c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790227b9626b4f2495f845feff024841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ea6404d6ba48f4a4238a261a2c340b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677f407111c54b68831b6160af1d00fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\loyle\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Defining the two major datasets: training and testing\n",
    "\n",
    "#transforms.ToTensor convers data to a tensor, not already available as a tensor\n",
    "train = datasets.MNIST(\"\",train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e21ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data into another object that lets us iterate over it\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10,shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10,shuffle=True)\n",
    "\n",
    "#About the dataset: MNIST is a hand-written numbers dataset from 0 to 9, 28x28 image of the dataset.\n",
    "#Batch size: how many samples/items we want to pass at a time to our model. Model will be optimized in tiny increments.\n",
    "#            Commonly 8 to 64. If we used all of the data at once, the machine might learn some generalizations but some\n",
    "#            weights might be more arbitrary and may not be generalizable.\n",
    "#Shuffle: If the data were fed to the machine in order, it would decide \"everything is a 0\" when it sees the zeros or\n",
    "#            \"everything is a 9\" when it reaches the 9. Shuffling helps with the generalization of the dataset. Minimizes\n",
    "#            overfitting and cutting corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8665433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([8, 5, 2, 3, 0, 3, 2, 9, 4, 4])]\n"
     ]
    }
   ],
   "source": [
    "#Iterating over the data\n",
    "\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c7d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "#Accessing the 0th tensor and then the 0th image; 1st tensor and 1st image\n",
    "\n",
    "x,y = data[0][0], data[1][0]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bae7f6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x149588f65b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "#The valid shape for an image needs to be something like [28,28]\n",
    "#plt.imshow(data[0][0]) #Throws an error because it's not the right shape\n",
    "plt.imshow(data[0][0].view(28,28)) #Shows an 8!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ccc75ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "#Balancing the dataset\n",
    "\n",
    "#as.optimizer tries to create loss as easily as possible as much as possible. An imbalanced dataset will make the model\n",
    "#adjust weights towards the majority dataset to minimize loss--> gets stuck and can't get out of the hole without an increse\n",
    "#in loss. \n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] +=1\n",
    "        total+=1\n",
    "        \n",
    "\n",
    "print(counter_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75e92452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "#Looking at percentage distribution: what percent does each number make up of the total dataset? Result: relatively balanced\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae09590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674841d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc0275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a194fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
